#!/bin/bash
# ‰ΩøÁî®‰øÆÂ§çÂíå‰ºòÂåñÁâàÊú¨ËøêË°å verify_deep_NFA.py

echo "=== Fixed & Optimized verify_deep_NFA.py Usage ==="
echo "‚úÖ Fixed dimension bugs"
echo "‚úÖ Fixed torch.compile compatibility"  
echo "‚úÖ Fixed deprecated functorch APIs"
echo "‚úÖ Memory optimized EGOP computation"
echo

echo "=== Recommended Usage ==="
echo
echo "1. Full accuracy (use ALL training samples, memory intensive):"
echo "python verify_deep_NFA.py --path MODEL_PATH"
echo

echo "2. Memory efficient (limit samples for Colab/limited memory):"
echo "python verify_deep_NFA.py --path MODEL_PATH --max_samples 10000"
echo

echo "3. Quick test (single layer, small sample):"
echo "python verify_deep_NFA.py --path MODEL_PATH --max_samples 5000 --layers 0"
echo

echo "4. Your specific model:"
echo "python verify_deep_NFA.py --path ./saved_nns/svhn:num_epochs:100:learning_rate:0.01:weight_decay:0:init:default:optimizer:muon:freeze:False:width:1024:depth:5:act:relu:val_interval:20:nn.pth"
echo

echo "5. Same model with memory limit:"
echo "python verify_deep_NFA.py --path ./saved_nns/svhn:num_epochs:100:learning_rate:0.01:weight_decay:0:init:default:optimizer:muon:freeze:False:width:1024:depth:5:act:relu:val_interval:20:nn.pth --max_samples 15000"
echo

echo "=== Key Fixes & Optimizations ==="
echo "üîß Fixed RuntimeError: matmul dimension mismatch"
echo "üîß Fixed data shape issues (ensures 2D tensors)"
echo "üîß Uses SAME training samples as in training (when --max_samples not specified)"
echo "‚ö° Streaming EGOP computation (no storing all Jacobians)"
echo "‚ö° Reduced batch size from 1000 to 200"
echo "‚ö° Automatic memory cleanup"
echo "‚ö° Progress reporting every 10 batches"
echo "üÜï Modern PyTorch APIs (torch.func instead of functorch)"
echo

echo "=== Memory Usage Guidelines ==="
echo "No limit (full dataset): Use for final accurate results"
echo "15000-20000 samples: Good balance of accuracy and memory (~8-12 GB)"
echo "10000 samples: Default for memory-limited environments (~4-8 GB)"
echo "5000 samples: Quick testing (~2-4 GB)"
